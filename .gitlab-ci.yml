image: ${ARTIFACTORY_SERVER}/dockerhub-remote/python:3.7-alpine

services:
  - ${ARTIFACTORY_SERVER}/dockerhub-remote/docker:dind

stages:
  - lint
  - smoke-tests
  - sprinkle-tests
  - droplets
  - release
  - post-release-tests
  - publish
  - admin

variables:
  GIT_SUBMODULE_STRATEGY: recursive

# validate Cloudformation templates with cfn-lint
run_cfn_lint:
  stage: lint
  tags:
    - docker-executor
  except:
    refs:
      - schedules
      - triggers
      - pipelines
  script:
    - cd cloud-tools/cfn-lint
    - pip install -r requirements.txt
    # need to override primitiveType for autoscaling.Tags.propagateAtLaunch
    - cfn-lint --template ../../supported/**/*.template --override-spec override_propagate.json

# validate README file(s) only contain links that respond with 200 OK
# this pre-release job only checks internal links to avoid failures
# when tag version is unpublished
run_link_checker:
  image: ${ARTIFACTORY_SERVER}/dockerhub-remote/node:10
  stage: smoke-tests
  tags:
    - docker-executor
  only:
    refs:
      # run only on release branch and develop
      - /^R.*/
      - develop
  except:
    refs:
      - schedules
      - triggers
      - pipelines
    variables:
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
  script:
    - make link_check

pre_release_test_job:
  stage: sprinkle-tests
  tags:
    - docker-executor
  only:
    refs:
      - main
  except:
    variables:
      - $ANALYTICS_MESSAGE_PROCESS == "true"
      - $ANALYTICS_SCRIPTS_PROCESS == "true"
      - $VERIFY_REGKEY_COUNT == "true"
      - $REAPER_RUN == "true"
      - $DAILY_TESTS_MONITOR == "true"
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
    refs:
      - schedules
      - triggers
      - pipelines
  variables:
    TEST_POLICY: automated-test-scripts/data/test_policies/pre_release_test.yaml
    STACK_TYPE: dewdrop-preproduction
  script:
    - pip install -r cloud-tools/master-job/requirements.txt
    - cloud-tools/master-job/sprinkler.py --test-plan $TEST_POLICY --token $CI_JOB_TOKEN --branch $CI_COMMIT_REF_NAME --stack-type $STACK_TYPE --project-id $CI_PROJECT_ID
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure

scheduled_test_job:
  stage: sprinkle-tests
  tags:
    - docker-executor
  only:
    - schedules
  except:
    variables:
      - $UPDATE_SCHEDULES == "true"
  variables:
    TEST_POLICY: set in schedule!
    STACK_TYPE: dewdrop-preproduction
  script:
    - pip install -r cloud-tools/master-job/requirements.txt
    - cloud-tools/master-job/sprinkler.py --test-plan $TEST_POLICY --token $CI_JOB_TOKEN --branch $CI_COMMIT_REF_NAME --stack-type $STACK_TYPE --project-id $CI_PROJECT_ID
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure

# This job gets triggered by the sprinkler.py script that get ran by the 'master_test_job' it ingests TEMPLATE_URL
# and TEMPLATE_PARAMETERS which are passed down by the sprinkler.py script. Using the variables runs dewdrop with
# the set environment variables
dewdrop_test_run:
  image: ${ARTIFACTORY_SERVER}/ecosystems-cloudsolutions-docker-dev/dewdrop:$DEWDROP_IMAGE_ID
  stage: droplets
  tags:
    - docker-executor
  variables:
    SSH_KEY: "$SSH_KEY"
    AWS_DEFAULT_REGION: "$AWS_DEFAULT_REGION"
    AWS_ACCESS_KEY_ID: "$AWS_ACCESS_KEY_ID"
    AWS_SECRET_ACCESS_KEY: "$AWS_SECRET_ACCESS_KEY"
    TEMPLATE_URL: "$TEMPLATE_URL"
    TEMPLATE_PARAMETERS: "$TEMPLATE_PARAMETERS"
    STACK_TYPE: "$STACK_TYPE"
    GITLAB_JOB_URL: "$CI_JOB_URL"
    GIT_SUBMODULE_STRATEGY: recursive
  only:
    variables:
      - $RUN_SCHEDULED_DEWDROP_TEST == "true"
  script:
    # the dewdrop image itself does not contain any test files, so ensure dewdrop
    # is run from the known location where test policies expect it to be
    # location: root of the cloud factory repository
    - pip install taskcat
    - if [ "$CLOUD_PROVIDER_ENVIRONMENT" == "aws_china" ]; then
    -   AWS_DEFAULT_REGION=$AWS_CHINA_DEFAULT_REGION
    -   AWS_ACCESS_KEY_ID=$AWS_CHINA_ACCESS_KEY_ID
    -   AWS_SECRET_ACCESS_KEY=$AWS_CHINA_SECRET_ACCESS_KEY
    - fi
    - python /dewdrop/dewdrop-docker.py
  artifacts:
    paths:
      - test_results/**/*
    when: always
    expire_in: 1 week

publish_to_github:
  image: ${ARTIFACTORY_SERVER}/dockerhub-remote/node:8
  stage: release
  only:
    - /(^publish-(v\d*[1-9]*\.)(\d*[1-9]*\.)(\d))/
  script:
    # install jq
    - apt-get update
    - apt-get install -y jq
    # Execute Release script to push source to github repo
    - ./cloud-tools/release-tool/publish_github.sh "$ALLOWED_DIRS" "$ALLOWED_FILES"
  variables:
    ALLOWED_DIRS: ".github AMI_Maps deploy experimental iApps images supported"
    ALLOWED_FILES: ".gitattributes README.md aws-bigip-version-matrix.md aws-troubleshooting.md aws-update-bigip-image.md iapp-migration.md  slack-channel-statement.md template-index.md"
    GITLAB_API_URL: "$AWS_URL"
    GITHUB_API_TOKEN: "$AWS_GITHUB_API_TOKEN"
    GITLAB_PRIVATE_TOKEN: "$AWS_GITLAB_API_TOKEN"

# validate README file(s) only contain links that respond with 200 OK
run_link_checker_release:
  image: ${ARTIFACTORY_SERVER}/dockerhub-remote/node:10
  stage: post-release-tests
  tags:
    - docker-executor
  only:
    # run only after release has been published
    - /(^publish-(v\d*[1-9]*\.)(\d*[1-9]*\.)(\d))/
  except:
    refs:
      - schedules
      - triggers
      - pipelines
    variables:
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
  script:
    - make link_check_release

# Check template version, then push the examples/ folder to S3 when a tag in the form of "aws-v1.0.1.0" is added to the main branch
publish_aws_templates_s3:
  image: ${ARTIFACTORY_SERVER}/dockerhub-remote/python:3
  stage: publish
  only:
    - /(^publish-(v\d*[1-9]*\.)(\d*[1-9]*\.)(\d))/
  script:
    - curl -sL https://deb.nodesource.com/setup_12.x | bash - && apt-get install -yq nodejs build-essential
    - npm install -g npm
    - apt-get install -y jq
    - pip3 install yq awscli
    - mkdir -p temp_s3
    - find supported -name '*.template' -exec cp {} ./temp_s3/ \;
    - find experimental -name '*.template' -exec cp {} ./temp_s3/ \;
    - aws s3 cp --recursive --acl public-read temp_s3 s3://f5-cft --metadata-directive REPLACE
  tags:
    - cm-official-docker-executor

# manually scheduled job to enable/disable daily scheduled test jobs
update_daily_test_schedules:
  image: ${ARTIFACTORY_SERVER}/dockerhub-remote/node:8
  stage: admin
  only:
    variables:
      - $UPDATE_SCHEDULES == "true"
  script:
    - apt-get update
    - apt-get install -y jq
    - ./cloud-tools/scheduler-tool/activate-schedule.sh
  variables:
    FILTER: "$FILTER"
    GIT_LAB_API_URL: "$AWS_URL"
    GIT_LAB_PRIVATE_TOKEN: "$AWS_GITLAB_API_TOKEN"
    STATE: "$STATE"
